# JobSeek

JobSeek is a modular, compliant job scraper designed to aggregate postings from public applicant tracking systems (ATS) such as Greenhouse, Lever, and Workday.  
It demonstrates clean architecture, scalability, and solid software design principlesâ€”making it both practical for job discovery and portfolio-ready as a software engineering project.

---

## Purpose
JobSeek helps job seekers surface relevant, high-quality postings efficiently while showcasing best practices in modular design, data ingestion, and filtering.

---

## Development Phases

### ðŸŸ© **Phase 1 â€” MVP (Current Focus)**
**Goal:** Build a minimal but scalable prototype that fetches jobs from Greenhouse and outputs them to the console and a CSV file.

**Scope:**
- **Source:** Greenhouse only  
- **Filters:** Experience level (Entry, Mid, Senior)  
- **Sorting:** Most recently posted jobs first  
- **Sinks (outputs):** Console and CSV  
- **Architecture:** Core domain + single source + two sinks  
- **CLI Commands:**  
  ```bash
  jobseek fetch --config config.yaml
  jobseek list --since 7d --sort recent
  jobseek export --format csv --out jobs.csv
  ```
- **Testing:**  
  - Unit tests for filters, sort, and CSV writer  
  - Mocked tests for Greenhouse parser  
- **Compliance:** Respect `robots.txt`; no LinkedIn scraping

This phase establishes the foundationâ€”ensuring the pipeline, normalization, and filtering logic work cleanly before expanding.

---

### ðŸŸ¨ **Phase 2 â€” Multi-Source & Filtering Expansion**
**Goal:** Introduce more sources and filtering logic while maintaining modularity.

**Planned Additions:**
- **New Sources:** Lever, Workday, and other ATS adapters  
- **Filters:** Location, title keywords, work mode (remote/hybrid/on-site), and salary  
- **Dedupe:** Detect and remove duplicates across ATS sources  
- **Storage:** Add SQLite sink for persistence and future querying  
- **Scheduling:** Implement `watch` mode for recurring scrapes (e.g., every 60 minutes)  
- **Ranking:** Recency + keyword-based relevance scoring

---

### ðŸŸ¦ **Phase 3 â€” Advanced Features & Web Interface**
**Goal:** Evolve JobSeek into a more automated and interactive job discovery tool.

**Planned Additions:**
- **Semantic relevance scoring** (e.g., sentence embeddings for matching keywords/skills)  
- **Web API & UI:** FastAPI backend + minimal React or Svelte frontend for browsing, saving, and tagging jobs  
- **Storage:** Transition to Postgres for multi-user or long-term data  
- **Scheduling & Automation:** GitHub Actions or containerized cron for periodic runs  
- **Compliance:** Configurable per-source opt-in and crawl delay enforcement  

---

## Architecture Overview
JobSeek uses a **Hexagonal (Ports & Adapters)** architecture for long-term scalability.

- **Domain Layer:** Core entities and interfaces  
  - `Job` model (normalized schema)  
  - `JobSource` and `JobSink` interfaces  
- **Application Layer:** Orchestrates the pipeline â€” fetch â†’ normalize â†’ filter â†’ sort â†’ sink  
- **Adapters:**  
  - *Sources* â€” platform-specific scrapers (Greenhouse, Lever, etc.)  
  - *Sinks* â€” output modules (Console, CSV, SQLite, Postgres)  
- **Config-Driven:** All behavior controlled by `config.yaml`  
- **Extensible:** Add new sources, filters, or sinks without modifying core logic

---

## Technology Stack
- **Language:** Python 3.12  
- **Core Libraries:** `httpx`, `asyncio`, `pydantic`, `Typer`  
- **Testing:** `pytest`  
- **Linting & Typing:** `ruff`, `mypy`  
- **CI/CD:** GitHub Actions (lint, type-check, tests, coverage badge)  
- **Future:** FastAPI (backend) + React (frontend)

---

## Compliance
- Respects each siteâ€™s `robots.txt` and usage terms  
- No automated scraping of LinkedIn or similar protected sources  
- Requests are rate-limited and opt-in per source  
- Legal considerations documented in `LEGAL.md`

---

## Roadmap Summary
| Phase | Focus | Key Deliverables |
|-------|--------|------------------|
| ðŸŸ© **1** | MVP | Greenhouse adapter, experience filter, console & CSV sinks |
| ðŸŸ¨ **2** | Multi-source expansion | Lever & Workday adapters, more filters, dedupe, SQLite sink |
| ðŸŸ¦ **3** | Advanced & UI | Semantic ranking, FastAPI + web UI, automation, Postgres |

---

## Project Structure
```
jobseek/
â”œâ”€â”€ domain/
â”‚   â””â”€â”€ models.py              # Core data types and interfaces
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ config.py              # Configuration parsing and schema
â”‚   â””â”€â”€ pipeline.py            # Main orchestration pipeline
â”œâ”€â”€ adapters/
â”‚   â”œâ”€â”€ sources/
â”‚   â”‚   â””â”€â”€ greenhouse.py      # Greenhouse source adapter
â”‚   â””â”€â”€ sinks/
â”‚       â”œâ”€â”€ console.py         # Console output
â”‚       â””â”€â”€ csvsink.py         # CSV output
â”œâ”€â”€ cli/
â”‚   â””â”€â”€ main.py                # Typer CLI entry point
â”œâ”€â”€ tests/
â”‚   â””â”€â”€ test_pipeline.py       # Unit and integration tests
â”œâ”€â”€ README.md
â””â”€â”€ LEGAL.md
```

---

## License & Disclaimer
JobSeek is an educational and portfolio project.  
Users are responsible for adhering to all relevant site terms and local regulations when running the scraper.
